{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 0: Import packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2055624, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bg_LTO_search.csv')\n",
    "\n",
    "# there are some entires with capitalized SearchMake and some in all lowercase, standardize the entries\n",
    "df['SearchMake'] = df['SearchMake'].str.lower()\n",
    "df['SearchModel'] = df['SearchModel'].str.lower()\n",
    "\n",
    "# after standardizing the format, unify the entires\n",
    "df=df.groupby(['SearchMake','SearchModel','Region','SearchCity']).agg({\"Total_Searches\":'sum'}).reset_index()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1919626, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get rid of dirty data - SearchMake or SearchModel with multiple sections \"|\"\n",
    "\n",
    "df_work = df[(~df.SearchMake.str.contains(\"\\|\",regex=True,na=False))|(~df.SearchModel.str.contains(\"\\|\",regex=True,na=False))].reset_index(drop=True)\n",
    "df_work.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1398659, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "\n",
    "df_work = df_work[(df_work.SearchMake != 'not used') & (df_work.SearchModel != 'not used')&(df_work.SearchCity != '(not set)')]\n",
    "df_work.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1398659, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_work = df_work.sort_values(by='Total_Searches',ascending=False).reset_index(drop=True)\n",
    "\n",
    "#longer version\n",
    "#df_work = df_work.sort_values(by='Total_Searches',ascending=False).reset_index(index=)\n",
    "#df_work.drop('index',axis=1,inplace=True)\n",
    "\n",
    "df_work.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New Brunswick', 'West New Britain Province']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code to look for provinces from the list\n",
    "list_of_region = df.Region.unique().tolist()\n",
    "[x for x in list_of_region if 'New B' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Useful code if you want to filter out non Canadian nor non American cities\n",
    "\n",
    "\n",
    "canada = ['British Columbia','Alberta','Saskatchewan','Manitoba','Ontario','Quebec','Newfoundland and Labrador',\n",
    "          'Nova Scotia','Prince Edward Island','New Brunswick','Nunavut','Northwest Territories','Yukon']\n",
    "\n",
    "#america = [\"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\n",
    "#  \"Connecticut\",\"Delaware\",\"Florida\",\"Georgia\",\"Hawaii\",\"Idaho\",\"Illinois\",\n",
    "#  \"Indiana\",\"Iowa\",\"Kansas\",\"Kentucky\",\"Louisiana\",\"Maine\",\"Maryland\",\n",
    "#  \"Massachusetts\",\"Michigan\",\"Minnesota\",\"Mississippi\",\"Missouri\",\"Montana\",\n",
    "#  \"Nebraska\",\"Nevada\",\"New Hampshire\",\"New Jersey\",\"New Mexico\",\"New York\",\n",
    "#  \"North Carolina\",\"North Dakota\",\"Ohio\",\"Oklahoma\",\"Oregon\",\"Pennsylvania\",\n",
    "#  \"Rhode Island\",\"South Carolina\",\"South Dakota\",\"Tennessee\",\"Texas\",\"Utah\",\n",
    "#  \"Vermont\",\"Virginia\",\"Washington\",\"West Virginia\",\"Wisconsin\",\"Wyoming\"]\n",
    "\n",
    "#df_work = df[(df.Region.isin(canada))|(df.Region.isin(america))] #filter the list by Canadian provinces\n",
    "#df_work.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group 'Maritimes' and Territories and American States into 'Other'\n",
    "Maritimes = ['Newfoundland and Labrador','Nova Scotia','Prince Edward Island','New Brunswick']\n",
    "Provinces = ['British Columbia','Alberta','Saskatchewan','Manitoba','Ontario','Quebec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work.loc[df_work.Region.isin(Maritimes),'Province'] = 'Maritimes' #Assign Maritimes\n",
    "df_work.loc[df_work.Region.isin(Provinces),'Province'] = df_work.Region\n",
    "df_work['Province'].fillna('Others', inplace=True) #If all else, assign \"Others\"\n",
    "\n",
    "### Alternative code based on if-else format\n",
    "#df['name_match'] = df['First_name'].apply(lambda x: 'Match' if x == 'Bill' else 'Mis-Match')\n",
    "\n",
    "#Try using .loc[row_indexer,col_indexer] = value instead\n",
    "#https://www.dataquest.io/blog/settingwithcopywarning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to see if it's working\n",
    "\n",
    "#df_work[df_work.Province.notnull()]\n",
    "#df_work[df_work['Province'] == 'Alberta']\n",
    "#df_work[(df_work['Province']!='Others')&(df_work['Province']!='Maritimes')].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Drayton Valley']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code to look for provinces from the list\n",
    "list_of_city = df_work[df_work['Province']!='Others'].SearchCity.unique().tolist()\n",
    "[x for x in list_of_city if 'Drayton Valley' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1398659, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_work.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Searches</th>\n",
       "      <th>% of Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25393305.0</td>\n",
       "      <td>54.349163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8078830.0</td>\n",
       "      <td>17.291079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5494081.0</td>\n",
       "      <td>11.758954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4079673.0</td>\n",
       "      <td>8.731704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1485176.0</td>\n",
       "      <td>3.178715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>918036.0</td>\n",
       "      <td>1.964868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>711447.0</td>\n",
       "      <td>1.522706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>561984.0</td>\n",
       "      <td>1.202812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>46722532.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Total_Searches  % of Total\n",
       "0          25393305.0   54.349163\n",
       "1           8078830.0   17.291079\n",
       "2           5494081.0   11.758954\n",
       "3           4079673.0    8.731704\n",
       "4           1485176.0    3.178715\n",
       "5            918036.0    1.964868\n",
       "6            711447.0    1.522706\n",
       "7            561984.0    1.202812\n",
       "Total      46722532.0  100.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del df_summary\n",
    "df_summary = df_work.groupby(\"Province\").agg({\"Total_Searches\":'sum'})\n",
    "df_summary= df_summary.sort_values(by='Total_Searches',ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_summary['% of Total'] = (df_summary['Total_Searches']/ df_summary['Total_Searches'].sum()*100)\n",
    "df_summary.loc['Total',:] = df_summary.sum().values\n",
    "\n",
    "\n",
    "df_summary\n",
    "\n",
    "### Alternative\n",
    "#table['% of Total'] = (table.C / table.C.sum() * 100)\n",
    "#table['% of B'] = (table.C / table.groupby(level=0).C.transform(sum) * 100)\n",
    "#table.loc['total', :] = table.sum().values\n",
    "\n",
    "#https://stackoverflow.com/questions/37148787/pandas-pivot-table-percent-calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "canadian_cities = pd.read_csv('data_canadian_cities.csv')\n",
    "canadian_cities.drop('location',axis=1,inplace=True)\n",
    "\n",
    "canadian_cities.loc[canadian_cities['population']>= 200000,'Category'] = 'Metro'\n",
    "canadian_cities.loc[(canadian_cities['population']>=50000)&(canadian_cities['population']<200000),'Category'] = 'Mid'\n",
    "canadian_cities['Category'].fillna('Rural', inplace=True) #If all else, assign \"Rural\"\n",
    "\n",
    "\n",
    "#canadian_cities.loc[(canadian_cities['population']>=50000) and (canadian_cities['population']<200000),'Category'] = 'Mid'\n",
    "#canadian_cities['Category'].fillna('Rural', inplace=True) #If all else, assign \"Others\"\n",
    "\n",
    "#canadian_cities[canadian_cities['Category']=='Rural'].sort_values(by='population',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asciiname</th>\n",
       "      <th>population</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Sainte-Catherine</td>\n",
       "      <td>16762</td>\n",
       "      <td>Rural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Sainte-Catherine</td>\n",
       "      <td>16211</td>\n",
       "      <td>Rural</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            asciiname  population Category\n",
       "204  Sainte-Catherine       16762    Rural\n",
       "210  Sainte-Catherine       16211    Rural"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canadian_cities.loc[canadian_cities.duplicated(subset=['asciiname'],keep=False), :]\n",
    "\n",
    "#As you can see there are two entries of the same asciiname, drop first then merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1398659, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canadian_cities.drop([210],inplace=True)\n",
    "df_work2 = pd.merge(df_work,canadian_cities, left_on ='SearchCity',right_on='asciiname',how='left')\n",
    "df_work2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09202037680663368"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_work2[df_work2.Category.isnull()].Total_Searches.sum()/df_work2.Total_Searches.sum()\n",
    "# nearly 10% of total searches are dropped from Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06201887774404007"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_work2[(df_work2.Category.isnull())&(df_work2.Province!='Others')].Total_Searches.sum()/df_work2.Total_Searches.sum()\n",
    "# nearly 6% of total searches from non-Other Provinces are dropped from Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### pick cities with more than 20,000 searches\n",
    "list_prep = df_work2[(df_work2.Category.isnull())&(df_work2.Region.isin(canada))]\n",
    "list_prep = list_prep.iloc[: , [3,4,5,8]]\n",
    "list_prep = list_prep.groupby(['SearchCity','Province']).agg({\"Total_Searches\":'sum'}).sort_values(by=['Total_Searches'],ascending=False).reset_index()\n",
    "\n",
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#    print(list_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Searches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6959.258993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19389.546183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>660.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1757.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4616.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>177576.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Total_Searches\n",
       "count      417.000000\n",
       "mean      6959.258993\n",
       "std      19389.546183\n",
       "min          1.000000\n",
       "25%        660.000000\n",
       "50%       1757.000000\n",
       "75%       4616.000000\n",
       "max     177576.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_prep.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1398659, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_prep = list_prep[list_prep['Total_Searches']>18000].reset_index() \n",
    "# make sure reset_index or groupby columns (Province, SearchCity) won't appear!!\n",
    "list_prep = list_prep['SearchCity'].tolist()\n",
    "\n",
    "#list_of_additional_cities\n",
    "#for col in list_of_additional_cities.columns: \n",
    "#    print(col) \n",
    "\n",
    "df_work2.loc[df_work2['SearchCity'].isin(list_prep),'Category'] = 'Mid'\n",
    "df_work2['Category'].fillna('Rural', inplace=True)\n",
    "\n",
    "df_work2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 9)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check to see any error values\n",
    "df_work2[df_work2.Category.isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(368069, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = df_work2.drop(['Region','SearchCity','asciiname','population'], axis=1)\n",
    "#df_final.to_csv('result.csv')\n",
    "df_final = df_final.groupby(['Province','Category','SearchMake','SearchModel']).agg({\"Total_Searches\":'sum'}).sort_values(by=['Total_Searches'],ascending=False).reset_index()\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = {i:dat for i, dat in df_final.groupby(['Province','Category'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province</th>\n",
       "      <th>Category</th>\n",
       "      <th>SearchMake</th>\n",
       "      <th>SearchModel</th>\n",
       "      <th>Total_Searches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ontario</td>\n",
       "      <td>Metro</td>\n",
       "      <td>bmw</td>\n",
       "      <td>3 series</td>\n",
       "      <td>342425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ontario</td>\n",
       "      <td>Metro</td>\n",
       "      <td>ford</td>\n",
       "      <td>mustang</td>\n",
       "      <td>304794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ontario</td>\n",
       "      <td>Metro</td>\n",
       "      <td>honda</td>\n",
       "      <td>civic</td>\n",
       "      <td>301238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ontario</td>\n",
       "      <td>Metro</td>\n",
       "      <td>mercedes-benz</td>\n",
       "      <td>c-class</td>\n",
       "      <td>268657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ontario</td>\n",
       "      <td>Metro</td>\n",
       "      <td>bmw</td>\n",
       "      <td>m</td>\n",
       "      <td>233715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province Category     SearchMake SearchModel  Total_Searches\n",
       "0  Ontario    Metro            bmw    3 series          342425\n",
       "1  Ontario    Metro           ford     mustang          304794\n",
       "2  Ontario    Metro          honda       civic          301238\n",
       "3  Ontario    Metro  mercedes-benz     c-class          268657\n",
       "4  Ontario    Metro            bmw           m          233715"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames['Ontario','Metro'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skato\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df_dir = df_work2.drop(['SearchMake','SearchModel','Region','Total_Searches','population'], axis=1).drop_duplicates()\n",
    "#df_dir.drop_duplicates()\n",
    "df_dir_list = df_dir.SearchCity[(df_dir.Category !='Rural')&(df_dir.Province=='Ontario')].reset_index(drop=True)\n",
    "df_dir_list.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csv\n",
    "\n",
    "#frames = {i:dat for i, dat in df_final.groupby('Province')}\n",
    "\n",
    "# with open('dict.csv', 'w') as csv_file:\n",
    "#     writer = csv.writer(csv_file)\n",
    "#     for key, value in frames.items():\n",
    "#        writer.writerow([key, value])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(list_of_province)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL Lesson - always check there is no duplicate entry in joining tables!<br>\n",
    "When I left joined df_work and canadian_cities (reference file) using df_work as the base table, row number increased from <br>\n",
    "<br>\n",
    "row # for df_work = 1,878,733 <br>\n",
    "row # for canadian_cities = 400 <br>\n",
    "<br>\n",
    "Theoretically, row# for df_work2 should be same as df_work (because left joint), but df_work2 = 1,880,685<br>\n",
    "1952 more rows in df_work2 than df_work!!!<br>\n",
    "<br>\n",
    "Two approaches were taken<br>\n",
    "1. Check # of rows where [SearchCity] = isnull & [asciiname] = notnull - 67 rows <br>\n",
    "df_work2[(df_work2['SearchCity'].isnull())&(df_work2['asciiname'].isnull())].shape<br><br>\n",
    "2. Check for duplicates from reference table - 1 duplicate found on canadian_cities <br>\n",
    "canadian_cities.loc[canadian_cities.duplicated(subset=['asciiname'],keep=False), :] <br>\n",
    "<br>As you can tell from below, population number is different! manually delete one of the two!\n",
    "<br><br>\n",
    "The duplicated entry from canadian_cities created 1952 duplicated entries on df_work2 once joined<br>\n",
    "df_work2.loc[df_work2.SearchCity =='Sainte-Catherine'].drop_duplicates(keep=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
